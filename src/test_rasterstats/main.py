# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import division
import numpy as np
import warnings
from affine import Affine
from shapely.geometry import shape
from .io import read_features, Raster
from .utils import (rasterize_geom, rasterize_pctcover_geom, get_percentile, check_stats,
                    remap_categories, key_assoc_val, boxify_points, get_latitude_scale)
from copy import copy

def raster_stats(*args, **kwargs):
    """Deprecated. Use zonal_stats instead."""
    warnings.warn("'raster_stats' is an alias to 'zonal_stats'"
                  " and will disappear in 1.0", DeprecationWarning)
    return zonal_stats(*args, **kwargs)


def zonal_stats(*args, **kwargs):
    """The primary zonal statistics entry point.

    All arguments are passed directly to ``gen_zonal_stats``.
    See its docstring for details.

    The only difference is that ``zonal_stats`` will
    return a list rather than a generator."""
    return list(gen_zonal_stats(*args, **kwargs))


def gen_zonal_stats(
    vectors, raster,
    layer=0,
    band_num=1,
    nodata=None,
    affine=None,
    stats=None,
    all_touched=False,
    percent_cover_scale=None,
    percent_cover_selection=None,
    percent_cover_weighting=False,
    latitude_correction=False,
    categorical=False,
    category_map=None,
    add_stats=None,
    raster_out=False,
    prefix=None,
    save_properties=False,
    geojson_out=False,
    **kwargs):
    """Zonal statistics of raster values aggregated to vector geometries.

    Parameters
    ----------
    vectors: path to an vector source or geo-like python objects

    raster: ndarray or path to a GDAL raster source
        If ndarray is passed, the ``affine`` kwarg is required.

    layer: int or string, optional
        If `vectors` is a path to an fiona source,
        specify the vector layer to use either by name or number.
        defaults to 0

    band_num: int, optional
        If `raster` is a GDAL source, the band number to use (counting from 1).
        defaults to 1.

    nodata: float, optional
        If `raster` is a GDAL source, this value overrides any NODATA value
        specified in the file's metadata.
        If `None`, the file's metadata's NODATA value (if any) will be used.
        defaults to `None`.

    affine: Affine instance
        required only for ndarrays, otherwise it is read from src

    stats:  list of str, or space-delimited str, optional
        Which statistics to calculate for each zone.
        All possible choices are listed in ``utils.VALID_STATS``.
        defaults to ``DEFAULT_STATS``, a subset of these.

    all_touched: bool, optional
        Whether to include every raster cell touched by a geometry, or only
        those having a center point within the polygon.
        defaults to `False`

    percent_cover_scale: int, optional
        Scale used when generating percent coverage estimates of each
        raster cell by vector feature. Percent coverage is generated by
        rasterizing the feature at a finer resolution than the raster
        (based on percent_cover_scale value) then using a summation to aggregate
        to the raster resolution and dividing by the square of percent_cover_scale
        to get percent coverage value for each cell. Increasing percent_cover_scale
        will increase the accuracy of percent coverage values; three orders
        magnitude finer resolution (percent_cover_scale=1000) is usually enough to
        get coverage estimates with <1% error in individual edge cells coverage
        estimates, though much smaller values (e.g., percent_cover_scale=10) are often
        sufficient (<10% error) and require less memory.

    percent_cover_selection: float, optional
        Include only raster cells that have at least the given percent
        covered by the vector feature. Requires percent_cover_scale argument
        be used to specify scale at which to generate percent coverage
        estimates

    percent_cover_weighting: bool, optional
        x

    latitude_correction: bool, optional
        * For use with WGS84 raster data only.
        * Only applies to "mean" stat.
        Weights cell values when generating statistics based on latitude
        (using haversin function) in order to account for actual area
        represented by pixel cell.

    categorical: bool, optional

    category_map: dict
        A dictionary mapping raster values to human-readable categorical names.
        Only applies when categorical is True

    add_stats: dict
        with names and functions of additional stats to compute, optional

    raster_out: boolean
        Include the masked numpy array for each feature?, optional

        Each feature dictionary will have the following additional keys:
        mini_raster_array: The clipped and masked numpy array
        mini_raster_affine: Affine transformation
        mini_raster_nodata: NoData Value

    prefix: string
        add a prefix to the keys (default: None)

    save_properties: boolean
        Returns original features along with specified stats when
        geojson_out is set to False.

    geojson_out: boolean
        Return list of GeoJSON-like features (default: False)
        Original feature geometry and properties will be retained
        with zonal stats appended as additional properties.
        Use with `prefix` to ensure unique and meaningful property names.

    Returns
    -------
    generator of dicts (if geojson_out is False)
        Each item corresponds to a single vector feature and
        contains keys for each of the specified stats.
        If save_properties is True, also contains original properties

    generator of geojson features (if geojson_out is True)
        GeoJSON-like Feature as python dict
    """
    stats, run_count = check_stats(stats, categorical)

    # Handle 1.0 deprecations
    transform = kwargs.get('transform')
    if transform:
        warnings.warn("GDAL-style transforms will disappear in 1.0. "
                      "Use affine=Affine.from_gdal(*transform) instead",
                      DeprecationWarning)
        if not affine:
            affine = Affine.from_gdal(*transform)

    ndv = kwargs.get('nodata_value')
    if ndv:
        warnings.warn("Use `nodata` instead of `nodata_value`", DeprecationWarning)
        if not nodata:
            nodata = ndv

    cp = kwargs.get('copy_properties')
    if cp:
        warnings.warn("Use `geojson_out` or `save_properties` to preserve feature properties",
                      DeprecationWarning)


    valid_percent_cover_stat = any([i in stats for i in ['mean', 'count', 'sum']])
    if percent_cover_weighting and not percent_cover_selection and not valid_percent_cover_stat:
        warnings.warn('`percent_cover_weighting` option selected but no stats which can use percent cover were selected')
        percent_cover_weighting = False


    percent_cover = False
    if percent_cover_weighting or percent_cover_selection is not None:

        percent_cover = True

        if percent_cover_scale is None:
            raise Exception('Value for `percent_cover_scale must be provided in order '
                            'to use percent_cover_weighting or percent_cover_selection')

        try:
            if percent_cover_scale != int(percent_cover_scale):
                warnings.warn('Value for `percent_cover_scale` given ({0}) '
                              'was converted to int ({1}) but does not '
                              'match original value'.format(
                                percent_cover_scale, int(percent_cover_scale)))

            percent_cover_scale = int(percent_cover_scale)

            if percent_cover_scale <= 1:
                raise Exception('Value for `percent_cover_scale` must be greater than one '
                                '({0})'.format(percent_cover_scale))

        except:
            raise Exception('Invalid value for `percent_cover_scale` provided '
                            '({0}). Must be type int.'.format(percent_cover_scale))

        if percent_cover_selection is not None:
            try:
                percent_cover_selection = float(percent_cover_selection)
            except:
                raise Exception('Invalid value for `percent_cover_selection` provided '
                                '({0}). Must be type float.'.format(percent_cover_selection))

        if not all_touched:
            warnings.warn('`all_touched` was not enabled but an option requiring '
                          'percent_cover calculations was selected. Automatically '
                          'enabling `all_touched`.')
        all_touched = True


    with Raster(raster, affine, nodata, band_num) as rast:
        features_iter = read_features(vectors, layer)
        for i, feat in enumerate(features_iter):
            geom = shape(feat['geometry'])
            feature_stats = {}

            if 'Point' in geom.type:
                percent_cover = False
                geom = boxify_points(geom, rast)

            geom_bounds = tuple(geom.bounds)


            try:
                fsrc = rast.read(bounds=geom_bounds)

                fsrc_nodata = copy(fsrc.nodata)
                fsrc_affine = copy(fsrc.affine)
                fsrc_shape = copy(fsrc.shape)

            except MemoryError:
                print "Memory Error (fsrc): \n"
                print feat['properties']
                continue



            if percent_cover:

                try:
                    rv_array = rasterize_pctcover_geom(
                        geom, shape=fsrc_shape, affine=fsrc_affine,
                        scale=percent_cover_scale)

                    assert rv_array.shape == fsrc_shape

                except MemoryError:
                    print "Memory Error (percent_cover rv_array: \n"
                    print feat['properties']
                    continue

            else:

                try:
                    # create ndarray of rasterized geometry
                    rv_array = rasterize_geom(
                        geom, shape=fsrc_shape, affine=fsrc_affine,
                        all_touched=all_touched)

                    assert rv_array.shape == fsrc_shape

                except MemoryError:
                    print "Memory Error (standard rv_array): \n"
                    print feat['properties']
                    continue



            try:
                # Mask the source data array with our current feature
                # we take the logical_not to flip 0<->1 for the correct mask effect
                # we also mask out nodata values explicitly
                if percent_cover_selection is not None:
                    masked = np.ma.MaskedArray(
                        fsrc.array,
                        mask=np.logical_or(
                            fsrc.array == fsrc_nodata,
                            np.logical_not(rv_array),
                            percent_cover > percent_cover_selection))
                else:
                    masked = np.ma.MaskedArray(
                        fsrc.array,
                        mask=np.logical_or(
                            fsrc.array == fsrc_nodata,
                            np.logical_not(rv_array)))


                print masked
                print rv_array
                print masked*rv_array
                print ~masked.mask * rv_array


            except MemoryError:
                print "Memory Error (masked): \n"
                print feat['properties']
                continue


###
            if latitude_correction and 'mean' in stats:
                latitude_scale = [
                    get_latitude_scale(fsrc_affine[5] - fsrc_affine[0] * (0.5 + i))
                    for i in range(fsrc_shape[0])
                ]

            # print 'raster all data {0}'.format(fsrc.array.size)
            # print 'raster no data vals {0}'.format(np.sum(fsrc.array == fsrc_nodata))
            # print 'vector {0}'.format(np.sum(rv_array > 0))
            # print 'vector no data {0}'.format(
            #     np.sum(
            #         ~np.ma.MaskedArray(
            #             rv_array,
            #             mask=(fsrc.array == fsrc_nodata)
            #         ).mask
            #     )
            # )
            # print 'masked not masked {0}'.format(np.sum(~masked.mask))
###

            if 'nodata' in stats:
                featmasked = np.ma.MaskedArray(fsrc.array, mask=np.logical_not(rv_array))
                feature_stats['nodata'] = float((featmasked == fsrc_nodata).sum())


            del fsrc

            if not percent_cover_weighting:
                del rv_array


            try:
                compressed = masked.compressed()

            except MemoryError:
                print "Memory Error (compressed): \n"
                print feat['properties']
                continue


            if len(compressed) == 0:
                # nothing here, fill with None and move on
                feature_stats = dict([(stat, None) for stat in stats])
                if 'count' in stats:  # special case, zero makes sense here
                    feature_stats['count'] = 0

            else:
                if run_count:
                    keys, counts = np.unique(compressed, return_counts=True)
                    pixel_count = dict(zip([np.asscalar(k) for k in keys],
                                       [np.asscalar(c) for c in counts]))
                    if categorical:
                        feature_stats = dict(pixel_count)
                        if category_map:
                            feature_stats = remap_categories(category_map, feature_stats)


                # if 'weighted_mean' in stats:
                #     if latitude_correction:
                #         feature_stats['weighted_mean'] = float(
                #             np.sum((masked.T * latitude_scale).T * raster_pctcover) /
                #             np.sum((~masked.mask.T * latitude_scale).T * raster_pctcover))
                #     else:
                #         feature_stats['weighted_mean'] = float(
                #             np.sum(masked * raster_pctcover) /
                #             np.sum(~masked.mask * raster_pctcover))
                # if 'weighted_count' in stats:
                #     print masked
                #     print raster_pctcover
                #     print masked*raster_pctcover
                #     print ~masked.mask * raster_pctcover
                #     feature_stats['weighted_count'] = float(np.sum(~masked.mask * raster_pctcover))
                # if 'weighted_sum' in stats:
                #     feature_stats['weighted_sum'] = float(np.sum(masked * raster_pctcover))


                if 'mean' in stats:
                    if percent_cover_weighting and latitude_correction:
                        feature_stats['mean'] = float(
                            np.sum((masked.T * latitude_scale).T * rv_array) /
                            np.sum((~masked.mask.T * latitude_scale).T * rv_array))
                    elif percent_cover_weighting:
                        feature_stats['mean'] = float(
                            np.sum(masked * rv_array) /
                            np.sum(~masked.mask * rv_array))
                    elif latitude_correction:
                        feature_stats['mean'] = float(
                            np.sum((masked.T * latitude_scale).T) /
                            np.sum(latitude_scale * (masked.shape[1] - np.sum(masked.mask, axis=1))))
                    else:
                        feature_stats['mean'] = float(compressed.mean())
                if 'count' in stats:
                    if percent_cover_weighting:
                        feature_stats['count'] = float(np.sum(~masked.mask * rv_array))
                    else:
                        feature_stats['count'] = int(len(compressed))
                if 'sum' in stats:
                    if percent_cover_weighting:
                        feature_stats['sum'] = float(np.sum(masked * rv_array))
                    else:
                        feature_stats['sum'] = float(compressed.sum())
                if 'min' in stats:
                    feature_stats['min'] = float(compressed.min())
                if 'max' in stats:
                    feature_stats['max'] = float(compressed.max())
                if 'std' in stats:
                    feature_stats['std'] = float(compressed.std())
                if 'median' in stats:
                    feature_stats['median'] = float(np.median(compressed))
                if 'majority' in stats:
                    feature_stats['majority'] = float(key_assoc_val(pixel_count, max))
                if 'minority' in stats:
                    feature_stats['minority'] = float(key_assoc_val(pixel_count, min))
                if 'unique' in stats:
                    feature_stats['unique'] = len(list(pixel_count.keys()))
                if 'range' in stats:
                    try:
                        rmin = feature_stats['min']
                    except KeyError:
                        rmin = float(compressed.min())
                    try:
                        rmax = feature_stats['max']
                    except KeyError:
                        rmax = float(compressed.max())
                    feature_stats['range'] = rmax - rmin

                for pctile in [s for s in stats if s.startswith('percentile_')]:
                    q = get_percentile(pctile)
                    pctarr = compressed
                    feature_stats[pctile] = np.percentile(pctarr, q)


            if add_stats is not None:
                for stat_name, stat_func in add_stats.items():
                        feature_stats[stat_name] = stat_func(masked)

            if raster_out:
                feature_stats['mini_raster_array'] = masked
                feature_stats['mini_raster_affine'] = fsrc_affine
                feature_stats['mini_raster_nodata'] = fsrc_nodata

            if prefix is not None:
                prefixed_feature_stats = {}
                for key, val in feature_stats.items():
                    newkey = "{}{}".format(prefix, key)
                    prefixed_feature_stats[newkey] = val
                feature_stats = prefixed_feature_stats

            if geojson_out or save_properties:
                for key, val in feature_stats.items():
                    if 'properties' not in feat:
                        feat['properties'] = {}
                    feat['properties'][key] = val

                if geojson_out:
                    yield feat
                else:
                    yield feat['properties']
            else:
                yield feature_stats
