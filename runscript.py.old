# runscript.py

import pandas as pd
import numpy as np
import os
import sys
import errno
# from sqlalchemy import create_engine
from copy import deepcopy
# from datetime import datetime
import time

import random
from shapely.geometry import Polygon, Point, shape, box
import shapefile

Ts = time.time()


arg = sys.argv

COUNTRY = "senegal"
abbr = "SEN"
DB = "senegal"

ITER = 1

PIXELSIZE = 0.1

base = "/home/usery/mcr"

AMP = base+"/"+COUNTRY+"/data/projects.tsv"
LOC = base+"/"+COUNTRY+"/data/locations.tsv"

SUBSET = 'ALL'

# must start at and inlcude ADM0
# all additional ADM shps must be included so that adm_path index corresponds to adm level
adm_paths = []
adm_paths.append(base+"/"+COUNTRY+"/shapefiles/ADM0/"+abbr+"_adm0.shp")
adm_paths.append(base+"/"+COUNTRY+"/shapefiles/ADM1/"+abbr+"_adm1.shp")
adm_paths.append(base+"/"+COUNTRY+"/shapefiles/ADM2/"+abbr+"_adm2.shp")

WORKING = base+"/"+COUNTRY+"/working/"+COUNTRY+"_"+SUBSET+"_"+str(PIXELSIZE)+"_"+str(ITER)+"-ITERATIONS"
INTERMEDIATE = WORKING+"/intermediate_rasters"
FINAL = WORKING+"/final_raster_products"

# create directories 

def make_dir(path):
	try: 
		os.makedirs(path)
	except OSError as exception:
		if exception.errno != errno.EEXIST:
			raise

make_dir(WORKING)
make_dir(INTERMEDIATE)
make_dir(FINAL)


# # drop/create postgres database and link to postgis
# echo 'creating postgres database '$DB
# dropdb $DB > /dev/null
# createdb $DB
# echo 'CREATE EXTENSION POSTGIS' | psql $DB
# echo '>>complete'
# echo

# # load ADM0 and AMD2 shps into postgis 
# echo 'loading reference geom shp to postgis database'
# shp2pgsql -I -s 4326 $ADM0 'ADM0' | psql -d $DB
# shp2pgsql -I -s 4326 $ADM2 'ADM2' | psql -d $DB
# echo '>>complete'
# echo

adm_shps = [shapefile.Reader(adm_path).shapes() for adm_path in adm_paths]

adm0 = shape(adm_shps[0][0])

(adm0_minx, adm0_miny, adm0_maxx, adm0_maxy) = adm0.bounds

import math
print (adm0_minx, adm0_miny, adm0_maxx, adm0_maxy)

pr = float(10)
prc = 1
nodata = -9999
(adm0_minx, adm0_miny, adm0_maxx, adm0_maxy) = (math.floor(adm0_minx*pr)/pr, math.floor(adm0_miny*pr)/pr, math.ceil(adm0_maxx*pr)/pr, math.ceil(adm0_maxy*pr)/pr)
print (adm0_minx, adm0_miny, adm0_maxx, adm0_maxy)

cols = np.arange(adm0_minx, adm0_maxx+(1.5/pr), 1/pr)
rows = np.arange(adm0_miny, adm0_maxy+(1.5/pr), 1/pr)
r_rows = reversed(rows)


# print cols
# print rows

op = {}

for r in rows:
	op[str(r)] = {}
	for c in cols:
		op[str(r)][str(c)] = 0.0

# op['14.0']['-12.0'] += 220398213.123
# print op['14.0']['-12.0']

# op = pd.DataFrame(index=reversed(rows),columns=cols)
# op = op.fillna(0)

# print op.at[14.0,-12.0]
# print op

asc = ""
asc += "NCOLS " + str(len(cols)) + "\n"
asc += "NROWS " + str(len(rows)) + "\n"
asc += "XLLCORNER " + str(adm0_minx) + "\n"
asc += "YLLCORNER " + str(adm0_miny) + "\n"
asc += "CELLSIZE " + str(1/pr) + "\n"
asc += "NODATA_VALUE " + str(nodata) + "\n"


# cx = adm0_minx
# while cx <= adm0_maxx:
# 	cy = adm0_miny

# 	while cy <= adm0_maxy:
# 		# print cx,cy
# 		cy += 1/pr 

# 	cx += 1/pr 
    

# for r in rows:
# 	for c in cols:
# 		asc += str(op[str(r)][str(c)]) 
# 		asc += " "
# 	asc += "\n"

# print asc


# sys.exit("tdone")


# # run setup script
# echo 'running python script that calculates random dollar ammounts and injects tables into postgres database'
# python pandas-setup.py $ITER $DB $AMP $LOC
# echo
# echo


# ======================================================================================================


#number of iterations
iterations = ITER
dbase = DB
amp_path = AMP
loc_path = LOC
# sector_codes = arg[5]

# print sector_codes
# type(sector_codes)

i_control = range(1, (int(iterations) + 1))

#--------------------------------------------------------------

# check csv delim and return if valid type
def getCSV(path):
    if path.endswith('.tsv'):
        return pd.read_csv(path, sep='\t', quotechar='\"')
    elif path.endswith('.csv'):
        return pd.read_csv(path, quotechar='\"')
    else:
        sys.exit('getCSV - file extension not recognized.\n')

# read input csv files into memory
amp = getCSV(amp_path)
loc = getCSV(loc_path)

if not "project_id" in amp or not "project_id" in loc:
	sys.exit("project_id fields not found in amp or loc files")

# create projectdata by merging amp and location files by project_id
merged = loc.merge(amp, on='project_id')

code_field = "precision_code"
if not code_field in merged or not "longitude" in merged or not "latitude" in merged:
	sys.exit("required fields not found")


# # connect to db
# print 'preparing load to postgres'
# engine = create_engine('postgresql://alex:postgrespass@localhost/' + dbase)

# # load projectdata into db table
# print 'loading initial table to postgres'
# merged.to_sql(('projectdata'), engine)

# # create dataframe for use in iterations
# column_list = ['iter', 'id', 'ran_dollars']
# dollar_table = pd.DataFrame(columns=column_list)

print "starting iterations ("+str(i_control)+" to be run)"


# mpi stuff
# for i in i_control:
i = 1

# print "iter "+str(i)+": starting"

# create dataframe for use in iterations
column_list = ['iter', 'id', 'ran_dollars']
dollar_table = pd.DataFrame(columns=column_list)

# create copy of merged project data
i_m = deepcopy(merged)

#add new column of random numbers (0-1)
i_m['ran_num'] = (pd.Series(np.random.random(len(i_m)))).values

#group merged table by project ID for the sum of each project ID's random numbers
grouped_random_series = i_m.groupby('project_id')['ran_num'].sum()


#create new empty dataframe
df_group_random = pd.DataFrame()

#add grouped random 'Series' to the newly created 'Dataframe' under a new grouped_random column
df_group_random['grouped_random'] = grouped_random_series

#add the series index, composed of project IDs, as a new column called project_ID
df_group_random['project_id'] = df_group_random.index


#now that we have project_ID in both the original merged 'Dataframe' and the new 'Dataframe' they can be merged
i_m = i_m.merge(df_group_random, on='project_id')

#calculate the random dollar ammount per point for each entry
i_m['random_dollars_pp'] = (i_m.ran_num / i_m.grouped_random) * i_m.total_commitments

# update dollar table with data for this iteration (iteration number, projects ids, and random dollars)
# dollar_table['iter'] = pd.Series([i]*len(i_m))
# dollar_table['id'] = i_m.project_location_id
# dollar_table['ran_dollars'] = i_m.random_dollars_pp

# append this version of dollar table to randomdata table in db
# dollar_table.to_sql('randomdata', engine, if_exists='append')

# print str(i) + 'complete'

print "iter "+str(1)+": random dollar calc complete"


print len(i_m)

# ======================================================================================================



# # add geom column to projectdata (from python setup script)
# echo "SELECT AddGeometryColumn('projectdata','geoms','4326','GEOMETRY',2);" | psql $DB
i_m["agg_type"] = ["None"] * len(i_m)
i_m["agg_geom"] = ["None"] * len(i_m)

# # add geoms to geom column based on precision code 
# # this will vary country to country but will always be of types point, buffer or adm poly

# echo "UPDATE projectdata SET geoms = (ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326)) WHERE projectdata.precision_code = 1" | psql $DB
# echo "UPDATE projectdata SET geoms = (ST_Buffer((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326))::geography, 25000)::geometry) WHERE projectdata.precision_code = 2" | psql $DB
# echo "UPDATE projectdata SET geoms = adm2.geom FROM adm2 WHERE (ST_Intersects((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326)),adm2.geom) is true AND projectdata.precision_code = 3)" | psql $DB
# echo "UPDATE projectdata SET geoms = adm2.geom FROM adm2 WHERE (ST_Intersects((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326)),adm2.geom) is true AND projectdata.precision_code = 4)" | psql $DB
# echo "UPDATE projectdata SET geoms = (ST_Buffer((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326))::geography, 25000)::geometry) WHERE projectdata.precision_code = 5" | psql $DB
# echo "UPDATE projectdata SET geoms = adm0.geom FROM adm0 WHERE (ST_Intersects((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326)),adm0.geom) is true AND projectdata.precision_code = 6)" | psql $DB
# echo "UPDATE projectdata SET geoms = adm0.geom FROM adm0 WHERE (ST_Intersects((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326)),adm0.geom) is true AND projectdata.precision_code = 7)" | psql $DB
# echo "UPDATE projectdata SET geoms = adm0.geom FROM adm0 WHERE (ST_Intersects((ST_SetSRID(ST_MakePoint(projectdata.longitude, projectdata.latitude), 4326)),adm0.geom) is true AND projectdata.precision_code = 8)" | psql $DB

agg_types = ["point","buffer","adm"]

lookup = {
	"1": {"type":"point","data":0},
	"2": {"type":"buffer","data":25000},
	"3": {"type":"adm","data":"2"},
	"4": {"type":"adm","data":"2"},
	"5": {"type":"buffer","data":25000},
	"6": {"type":"adm","data":"0"},
	"7": {"type":"adm","data":"0"},
	"8": {"type":"adm","data":"0"}
}


def getPolyWithin(item, polys):
	c = 0
	for shp in polys:
		tmp_shp = shape(shp)
		if item.within(tmp_shp):
			return tmp_shp

	return c


def inCountry(shp):
	return shp.within(adm0)


def getGeom(code, lon, lat):
	tmp_pnt = Point(lon, lat)
	
	if not inCountry(tmp_pnt):
		print "point not in country"
		return 0

	elif lookup[code]["type"] == "point":
		return tmp_pnt

	elif lookup[code]["type"] == "buffer":
		try:
			tmp_int = int(lookup[code]["data"])
			tmp_buffer = tmp_pnt.buffer(tmp_int)

			if inCountry(tmp_buffer):
				return tmp_buffer
			else:
				return tmp_buffer.intersection(adm0)

		except:
			print "buffer value could not be converted to int"
			return 0

	elif lookup[code]["type"] == "adm":
		try:
			tmp_int = int(lookup[code]["data"])
			return getPolyWithin(tmp_pnt, adm_shps[tmp_int])

		except:
			print "adm value could not be converted to int"
			return 0

	else:
		print "code type not recognized"
		return 0


def geomType(code):
	if str(code) in lookup:
		tmp_type = lookup[str(code)]["type"]
		return tmp_type

	else:
		print "code not recognized"
		return "None"


def geomVal(agg_type, code, lon, lat):
	if agg_type in agg_types:

		tmp_geom = getGeom(str(code), lon, lat)

		if tmp_geom != 0:
			# i[1]["agg_geom"] = tmp_geom
			return tmp_geom

		return "None"

		# print i[1]["agg_geom"]
		# if lookup[i[code_field].type] == "buffer" and not i["agg_geom"].within(adm0):
		# 	i["agg_geom"] = i["agg_geom"].intersection(adm0)

	else:
		print "agg_type not recognized"
		return "None"
		# i[1]["agg_type"] = "None"

i_m.agg_type = i_m.apply(lambda x: geomType(x[code_field]), axis=1)
i_m.agg_geom = i_m.apply(lambda x: geomVal(x.agg_type, x[code_field], x.longitude, x.latitude), axis=1)

print "iter "+str(1)+": get geom complete"


# for i in i_m.iterrows():
# 	if str(i[1][code_field]) in lookup:
# 		i[1]["agg_type"] = lookup[str(i[1][code_field])]["type"]
# 		tmp_geom = getGeom(str(i[1][code_field]), i[1].longitude, i[1].latitude)

# 		if tmp_geom != 0:
# 			i[1]["agg_geom"] = tmp_geom

# 		# print i[1]["agg_geom"]
# 		# if lookup[i[code_field].type] == "buffer" and not i["agg_geom"].within(adm0):
# 		# 	i["agg_geom"] = i["agg_geom"].intersection(adm0)

# 	else:
# 		print "code not recognized"
# 		# i[1]["agg_type"] = "None"
# 		# i[1]["agg_geom"] = "None"


# echo 'clipping geometries by country perimeter'
# echo "UPDATE projectdata SET geoms = (ST_Intersection(projectdata.geoms, adm0.geom)) FROM adm0 WHERE projectdata.precision_code = 2 OR projectdata.precision_code = 5" | psql $DB

# get rid of data without geom
# echo "DELETE FROM projectdata WHERE geoms IS NULL" | psql $DB
i_mx = i_m.loc[i_m.agg_geom != "None"].copy(deep=True)

print "iter "+str(1)+": remove empty geoms complete"


# print i_mx
# sys.exit("xstop")

# # create index
# echo 'creating spatial index'
# echo "CREATE INDEX spidx ON projectdata USING GIST (geoms)" | psql $DB
# echo "VACUUM ANALYZE projectdata" | psql $DB

# add point gen function
INVALID_X = -9999
INVALID_Y = -9999

def get_random_point_in_polygon(poly):
    (minx, miny, maxx, maxy) = poly.bounds
    p = Point(INVALID_X, INVALID_Y)
    px = 0
    while not poly.contains(p):
        p_x = random.uniform(minx, maxx)
        p_y = random.uniform(miny, maxy)
        p = Point(p_x, p_y)
    return p


# # generate random points
# echo 'generating random points within geometries'

# # add random points column to table
# echo "SELECT AddGeometryColumn('randomdata','ran_pts','4326','POINT',2);" | psql $DB


i_mx["rnd_pt"] = [0] * len(i_mx)
# i_mx["rnd_x"] = [0] * len(i_mx)
# i_mx["rnd_y"] = [0] * len(i_mx)


# # set points for precision code 1
# echo 'UPDATE randomdata SET ran_pts = projectdata.geoms FROM projectdata WHERE "project_location_id" = randomdata.id AND precision_code = 1' | psql $DB

# # add random points within specific geoms for points where precision code is not 1
# echo 'UPDATE randomdata SET ran_pts = RandomPointsInPolygon(projectdata.geoms, 1) FROM projectdata WHERE "project_location_id" = randomdata.id AND precision_code != 1' | psql $DB

# # remove random points not within ADM0 bounds for initial iteration
# echo 'DELETE FROM randomdata WHERE randomdata.id NOT IN (SELECT randomdata.id FROM randomdata, adm0 WHERE ST_Intersects(randomdata.ran_pts, adm0.geom) and iter=1)'


# i_mx.rnd_pt.loc[i_mx.agg_type == "point"] = i_mx.loc[i_mx.agg_type == "point"].agg_geom

# for i in i_mx[i_mx.agg_type != "point"].iterrows():
# 	i[1].rnd_pt, i[1].rnd_x, i[1].rnd_y = get_random_point_in_polygon(i[1].agg_geom)

def addPt(agg_type, agg_geom):
	if agg_type == "point":
		return agg_geom # pd.Series({'rnd_pt':agg_geom, 'rnd_x':1, 'rnd_y':2})
	else:
		tmp_rnd = get_random_point_in_polygon(agg_geom)
		return tmp_rnd # pd.Series({'rnd_pt':tmp_rnd, 'rnd_x':1, 'rnd_y':2}})

i_mx.rnd_pt = i_mx.apply(lambda x: addPt(x.agg_type, x.agg_geom), axis=1)

print "iter "+str(1)+": get rnd pts complete"

# i_mx.rnd_x = i_mx.apply(lambda p: (p.x), axis=1)
# i_mx.rnd_y = i_mx.apply(lambda p: (p.y), axis=1)

# def getXY(pt):
	# return pd.Series({"rnd_x":pt.x, "rnd_y":pt.y})

# i_mx = i_mx.merge(i_mx.apply(lambda s: addPt(s)), left_index=True, right_index=True)

i_mx = i_mx.merge(i_mx.rnd_pt.apply(lambda s: pd.Series({'rnd_x':round(s.x,prc), 'rnd_y':round(s.y,prc)})), left_index=True, right_index=True)

# for i in i_mx.iterrows():
	# print i[1].rnd_pt.x
	# print i[1].rnd_pt
	# print Point(i[1].rnd_pt)


# 
# create point grid for country
# 

# get adm0 bounding box
# create grid based on output resolution (pixel size) 
# initialize grid with 0

# round rnd_pts to match point grid
# add commitment value for each rnd pt to grid value


for i in i_mx.iterrows():
	nx = str(i[1].rnd_x)
	ny = str(i[1].rnd_y)
	# print nx, ny, op[nx][ny]
	op[ny][nx] += i[1].random_dollars_pp

print "iter "+str(1)+": add random_dollars_pp to op complete"


for r in r_rows:
	for c in cols:
		asc += str(op[str(r)][str(c)]) 
		asc += " "
	asc += "\n"

fout = open('/home/usery/mcr/output_test1.asc', 'w')
fout.write(asc)

print "iter "+str(1)+": update and write asc complete"

print op
# print i_mx
# print len(i_mx)


Tloc = int(time.time() - Ts)
print '\t\tRuntime Loc: ' + str(Tloc//60) +'m '+ str(int(Tloc%60)) +'s'


# ======================================================================================================



# # create base reference raster
# echo 'creating reference raster'
# echo 'CREATE TABLE rasterref AS SELECT ST_AsRaster((ST_Buffer((geom)::geography, 8000)::geometry), '$PIXELSIZE', '$PIXELSIZE') rast FROM adm0' | psql $DB
# echo "copy ( select encode(st_astiff(rast),'hex') from rasterref ) to stdout;" | psql $DB | xxd -p > $FINAL'/full_area_raster.tif'


# # create corner points to ensure bounding box
# echo 'creating table for raster iterations'
# echo "create table boxpts1 as select st_setsrid(st_makepoint(st_xmin(a.geom)-1.5, st_ymin(a.geom)-1.5), 4326) from adm0 as a" | psql $DB
# echo "create table boxpts2 as select st_setsrid(st_makepoint(st_xmin(a.geom)-1.5, st_ymax(a.geom)+1.5), 4326) from adm0 as a" | psql $DB
# echo "create table boxpts3 as select st_setsrid(st_makepoint(st_xmax(a.geom)+1.5, st_ymin(a.geom)-1.5), 4326) from adm0 as a" | psql $DB
# echo "create table boxpts4 as select st_setsrid(st_makepoint(st_xmax(a.geom)+1.5, st_ymax(a.geom)+1.5), 4326) from adm0 as a" | psql $DB


# # run number of desire iterations
# for iternum in $( seq 1 $ITER );do

#   # add corner points to random points
#   echo "inserting boundary points for raster production: $iternum"
#   echo "insert into randomdata(iter, ran_pts) select $iternum, st_setsrid from boxpts1" | psql $DB
#   echo "insert into randomdata(iter, ran_pts) select $iternum, st_setsrid from boxpts2" | psql $DB
#   echo "insert into randomdata(iter, ran_pts) select $iternum, st_setsrid from boxpts3" | psql $DB
#   echo "insert into randomdata(iter, ran_pts) select $iternum, st_setsrid from boxpts4" | psql $DB

#   # create temp tables and add random points
#   echo "this is iter $iternum"
#   echo "CREATE TABLE sum_iter_$iternum AS SELECT ST_Union(ST_AsRaster(ran_pts, (SELECT rast FROM rasterref), '32BF', ran_dollars, -9999), 'SUM') rast FROM randomdata WHERE randomdata.iter = $iternum" | psql $DB
#   echo "CREATE TABLE count_iter_$iternum AS SELECT ST_Union(ST_AsRaster(ran_pts, (SELECT rast FROM rasterref), '32BF', ran_dollars, -9999), 'COUNT') rast FROM randomdata WHERE randomdata.iter = $iternum" | psql $DB

#   # output temp tables to raster
#   echo "copy ( select encode(st_astiff(rast),'hex') from sum_iter_$iternum ) to stdout;" | psql $DB | xxd -p -r > $INTERMEDIATE'/sum_'$iternum'.tif'
#   echo "copy ( select encode(st_astiff(rast),'hex') from count_iter_$iternum ) to stdout;" | psql $DB | xxd -p -r > $INTERMEDIATE'/count_'$iternum'.tif'

#   # drop temp tables
#   echo "drop table sum_iter_$iternum" | psql $DB
#   echo "drop table count_iter_$iternum" | psql $DB
#   echo "iter $iternum complete"

# done


# # run final stats script
# python final-stats.py $INTERMEDIATE $FINAL
# echo '>>final stats script complete'



# ======================================================================================================



# import os, sys, glob, fnmatch
# import numpy as np
# from osgeo import gdal

# gdal.AllRegister()

# arg = sys.argv

# #---------------------------------------
# inputfolder = arg[1]
# outputfolder = arg[2]
# count_wildcard = 'count*.tif'
# sum_wildcard = 'sum*.tif'
# #---------------------------------------

# if not os.path.exists(outputfolder):
#     os.makedirs(outputfolder)

# projectdir_count = os.path.join(inputfolder, count_wildcard)
# projectdir_sum = os.path.join(inputfolder, sum_wildcard)

# filecontents_count = glob.glob(projectdir_count)
# filecontents_sum = glob.glob(projectdir_sum)

# #---------------------------------------
# layers_count = []
# x = 0
# for raster in filecontents_count:
#     x += 1
#     ds = gdal.Open(raster)
#     ds_array = ds.GetRasterBand(1).ReadAsArray()
#     layers_count.append(ds_array)
#     (rowtest, columntest) = np.shape(ds_array)
#     if x > 1:
#         if (rowtest, columntest) != (rowtestlast, columntestlast):
#             print 'count iteration ' + str(x) + ' was shaped as (' + str(rowtest) + ',' + str(columntest) + ')'
#     rowtestlast, columntestlast = rowtest, columntest
# del rowtest, columntest

# stack_count = np.dstack(layers_count)

# std_count = np.std(stack_count, axis=2)
# mean_count = np.mean(stack_count, axis=2)

# #---------------------------------------

# (row, column) = np.shape(mean_count)

# filename= outputfolder + '/std_count.tif'
# currentraster= gdal.GetDriverByName('GTiff').Create(filename, column, row, 1, gdal.GDT_Float64)
# currentraster.GetRasterBand(1).WriteArray(std_count)
# currentraster = None
# del currentraster, filename

# filename= outputfolder + '/mean_count.tif'
# currentraster= gdal.GetDriverByName('GTiff').Create(filename, column, row, 1, gdal.GDT_Float64)
# currentraster.GetRasterBand(1).WriteArray(mean_count)
# currentraster = None
# del currentraster, filename

# #---------------------------------------
# layers_sum = []
# x = 0
# for raster in filecontents_sum:
#     x += 1
#     ds = gdal.Open(raster)
#     ds_array = ds.GetRasterBand(1).ReadAsArray()
#     layers_sum.append(ds_array)
#     (rowtest, columntest) = np.shape(ds_array)
#     if x > 1:
#         if (rowtest, columntest) != (rowtestlast, columntestlast):
#             print 'sum iteration ' + str(x) + ' was shaped as (' + str(rowtest) + ',' + str(columntest) + ')'
#     rowtestlast, columntestlast = rowtest, columntest

# stack_sum = np.dstack(layers_sum)

# std_sum = np.std(stack_sum, axis=2)
# mean_sum = np.mean(stack_sum, axis=2)

# #---------------------------------------

# (row, column) = np.shape(mean_sum)

# filename= outputfolder + '/std_sum.tif'
# currentraster= gdal.GetDriverByName('GTiff').Create(filename, column, row, 1, gdal.GDT_Float64)
# currentraster.GetRasterBand(1).WriteArray(std_sum)
# currentraster = None
# del currentraster, filename

# filename= outputfolder + '/mean_sum.tif'
# currentraster= gdal.GetDriverByName('GTiff').Create(filename, column, row, 1, gdal.GDT_Float64)
# currentraster.GetRasterBand(1).WriteArray(mean_sum)
# currentraster = None
# del currentraster, filename

# #---------------------------------------
# print 'complete'



# ======================================================================================================



# # get new corner points
# XMIN=$(echo "select st_xmin(a.geom)-0.5 from adm0 as a" | psql $DB | sed '3q;d')
# XMAX=$(echo "select st_xmax(a.geom)+0.5 from adm0 as a" | psql $DB | sed '3q;d')
# YMIN=$(echo "select st_ymin(a.geom)-0.5 from adm0 as a" | psql $DB | sed '3q;d')
# YMAX=$(echo "select st_ymax(a.geom)+0.5 from adm0 as a" | psql $DB | sed '3q;d')

# echo $XMIN, $XMAX, $YMIN, $YMAX

# # generate projection file
# # sudo apt-get install geotiff-bin
# listgeo -tfw $INTERMEDIATE'/count_1.tif'

# # copy projection file for each output file
# cp $INTERMEDIATE'/count_1.tfw' $FINAL'/mean_count.tfw'
# cp $INTERMEDIATE'/count_1.tfw' $FINAL'/std_count.tfw'
# cp $INTERMEDIATE'/count_1.tfw' $FINAL'/mean_sum.tfw'
# cp $INTERMEDIATE'/count_1.tfw' $FINAL'/std_sum.tfw'

# # reproject each output
# gdal_edit.py -a_srs EPSG:4326 $FINAL'/mean_count.tif'
# gdal_edit.py -a_srs EPSG:4326 $FINAL'/std_count.tif'
# gdal_edit.py -a_srs EPSG:4326 $FINAL'/mean_sum.tif'
# gdal_edit.py -a_srs EPSG:4326 $FINAL'/std_sum.tif'

# echo "upper left is "$XMIN" , "$YMAX
# echo "lower left is "$XMAX" , "$YMIN

# # clip final outputs to remove corner points
# # coordinates are backwards (ymin and ymax) because of something strange in the raster gen process that flips the ymin/ymax values
# gdal_translate -projwin $XMIN $YMIN $XMAX $YMAX $FINAL'/mean_count.tif' $FINAL'/'$COUNTRY'_'$SUBSET'_mean_count.tif'
# gdal_translate -projwin $XMIN $YMIN $XMAX $YMAX $FINAL'/std_count.tif' $FINAL'/'$COUNTRY'_'$SUBSET'_std_count.tif'
# gdal_translate -projwin $XMIN $YMIN $XMAX $YMAX $FINAL'/mean_sum.tif' $FINAL'/'$COUNTRY'_'$SUBSET'_mean_sum.tif'
# gdal_translate -projwin $XMIN $YMIN $XMAX $YMAX $FINAL'/std_sum.tif' $FINAL'/'$COUNTRY'_'$SUBSET'_std_sum.tif'

# # clean up
# rm $FINAL'/mean_count.tif'
# rm $FINAL'/std_count.tif'
# rm $FINAL'/mean_sum.tif'
# rm $FINAL'/std_sum.tif'

# echo '>>georeferencing complete'
# echo

# # clean up
# rm -rf $INTERMEDIATE


# ======================================================================================================



